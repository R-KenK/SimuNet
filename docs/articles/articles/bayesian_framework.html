<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- Inform modern browsers that this page supports both dark and light color schemes,
  and the page author prefers light. --><meta name="color-scheme" content="dark light">
<script>
  // If `prefers-color-scheme` is not supported, fall back to light mode.
  // i.e. In this case, inject the `light` CSS before the others, with
  // no media filter so that it will be downloaded with highest priority.
  if (window.matchMedia("(prefers-color-scheme: dark)").media === "not all") {
    document.documentElement.style.display = "none";
    document.head.insertAdjacentHTML(
      "beforeend",
      "<link id=\"css\" rel=\"stylesheet\" href=\"https://bootswatch.com/3/flatly/bootstrap.css\" onload=\"document.documentElement.style.display = ''\">"
    );
  }
</script><title>`SimuNet`'s Bayesian framework • SimuNet</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- Flatly Theme - Light  --><link id="css-light" rel="stylesheet" href="https://bootswatch.com/3/flatly/bootstrap.css" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
<!-- Darkly Theme - Dark --><link id="css-dark" rel="stylesheet" href="https://bootswatch.com/3/darkly/bootstrap.css" media="(prefers-color-scheme: dark)">
<!-- preferably CSS --><link rel="stylesheet" href="../../preferably.css">
<link id="css-code-light" rel="stylesheet" href="../../code-color-scheme-light.css" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)">
<link id="css-code-dark" rel="stylesheet" href="../../code-color-scheme-dark.css" media="(prefers-color-scheme: dark)">
<script src="../../darkswitch.js"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../../bootstrap-toc.css">
<script src="../../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><meta property="og:title" content="`SimuNet`'s Bayesian framework">
<meta property="og:description" content="SimuNet">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../index.html">SimuNet</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">2.3.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../../articles/articles/SimuNet.html">Get started</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    How to use
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">First steps</li>
    <li>
      <a href="../../articles/articles/importing_networks.html">Importing networks</a>
    </li>
    <li>
      <a href="../../articles/articles/first_simulations.html">First simulations</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Performing experiments</li>
    <li>
      <a href="../../articles/articles/design_exp.html">General approach</a>
    </li>
    <li>
      <a href="../../articles/articles/sampling.html">Sampling methods</a>
    </li>
    <li>
      <a href="../../articles/articles/experiments.html">Experimental manipulations</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">SimuNet in details</li>
    <li>
      <a href="../../articles/articles/uncertainty.html">Network Uncertainty</a>
    </li>
    <li>
      <a href="../../articles/articles/bayesian_framework.html">SimuNet's Bayesian framework</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../reference/index.html">Documentation</a>
</li>
<li>
  <a href="../../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
          <a href="#" id="css-toggle-btn">
            <span class="fas fa-adjust fa-lg"></span>
          </a>
        </li>
        
        <li>
  <a href="https://github.com/R-KenK/SimuNet/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.macintoshlab.com/members">
    <span class="fa fa-user"></span>
     
  </a>
</li>
        
        


      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="bayesian_framework_files/header-attrs-2.9/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>
<code>SimuNet</code>’s Bayesian framework</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/R-KenK/SimuNet/blob/master/vignettes/articles/bayesian_framework.Rmd"><code>vignettes/articles/bayesian_framework.Rmd</code></a></small>
      <div class="hidden name"><code>bayesian_framework.Rmd</code></div>

    </div>

    
    
<div id="the-ideas-behind-simunets-bayesian-approach" class="section level1">
<h1 class="hasAnchor">
<a href="#the-ideas-behind-simunets-bayesian-approach" class="anchor"></a>The ideas behind <code>SimuNet</code>’s Bayesian approach</h1>
<p>In this article, we discuss what are the underlying ideas that led us to adopt the Bayesian approach at the core of <code>SimuNet</code>’s simulations.</p>
<div id="binomial-edge-weights" class="section level2">
<h2 class="hasAnchor">
<a href="#binomial-edge-weights" class="anchor"></a>“Binomial” edge weights</h2>
<p><code>SimuNet</code> simulates weighted networks by adopting a “binomial” approach to edge weights:</p>
<div id="edge-weights-often-starts-binary" class="section level3">
<h3 class="hasAnchor">
<a href="#edge-weights-often-starts-binary" class="anchor"></a>Edge weights often starts binary</h3>
<p>It is common with weighted (animal) social networks to quantify edge weights by accumulating social data that are inherently <strong>binary</strong>:</p>
<ul>
<li>for instance during <strong>scan sampling</strong>, edges are evaluated and are either 0 or 1</li>
<li>for <strong>continuous sampling</strong>:
<ul>
<li>an edge is either present or not when the association/interaction is comparable to a <strong>state</strong> (e.g. behind in contact)</li>
<li>the case of <strong>quasi-instantaneous events</strong> differs a little from a binary outcome. Usually then, it is the number of events over a given amount of time that serve as the edge weight. However, we argue that, realistically, continuous sampling can always be segmented according to a minimum unit of time, during which the event occurs or not, therefore binarizing the event</li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#TODO: schematic binary nature of edges in scan and continuous sampling</span></code></pre></div>
</div>
<div id="binomial-variables-and-edge-weights-similarities-and-differences" class="section level3">
<h3 class="hasAnchor">
<a href="#binomial-variables-and-edge-weights-similarities-and-differences" class="anchor"></a>Binomial variables and edge weights: similarities and differences</h3>
<div id="binomial-variables-a-summary" class="section level4">
<h4 class="hasAnchor">
<a href="#binomial-variables-a-summary" class="anchor"></a>Binomial variables: a summary</h4>
<p>Under this assumption that an edge is either 0 or 1 at each scan/unit of time and that the edge weight is then the sum of 1s, we propose that edge weights can be viewed as “binomial”:</p>
<ul>
<li>a binomial variable <span class="math inline">\(X \sim Binomial(n,p)\)</span> can be viewed as the sum <span class="math inline">\(X = \Sigma x_i, i \in [\![1,n]\!]\)</span> of Bernoulli variables <span class="math inline">\(x_i \sim Bernoulli(p), iid.\)</span>
</li>
<li>Similarly, an edge weight obtained as the sum of binary outcome <em>could</em> be obtained after summing binary variables.</li>
</ul>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#TODO: schematic analogy coin-tosses and edge weights</span></code></pre></div>
<p>This however raises questions regarding what differs with a purely binomial process, or requires additional assumptions to be met:</p>
</div>
<div id="the-case-of-static-networks" class="section level4">
<h4 class="hasAnchor">
<a href="#the-case-of-static-networks" class="anchor"></a>The case of static networks</h4>
<p>Static networks imply several assumption that allows for an easy “Binomial” approach to edge weights:</p>
<ol style="list-style-type: decimal">
<li>With a binomial variable, <span class="math inline">\(p\)</span> is considered <strong>constant</strong>: we argue that when constructing static weighted networks, it is assumed/approximated (consciously or not) that the properties of the group, and therefore the social network, <strong>do not change significantly</strong> over the course of data acquisition. If such probability of an edge being present existed (i.e. a probability of two nodes associating/interacting during a scan), adopting a static weighted network approach would assume that <span class="math inline">\(p\)</span> is constant.</li>
<li>Similarly, a static weighted network approach assumes no significant influence of time: considering <strong>each scan as independent from the others</strong> is an assumption to make, but one that could potentially already made when one build a static weighted network approach without being interested in how the networks are generated.</li>
</ol>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#TODO: schematic static network</span></code></pre></div>
</div>
<div id="the-case-of-dynamic-networks" class="section level4">
<h4 class="hasAnchor">
<a href="#the-case-of-dynamic-networks" class="anchor"></a>The case of dynamic networks</h4>
<p>Considering dynamic networks, such a Binomial approach could still hold under the assumption that <span class="math inline">\(p\)</span> would be variable through time:</p>
<ol start="3" style="list-style-type: decimal">
<li>Despite the many temporal or temporally-dependent drivers of two individuals associating, at the time of sampling, this could similarly result in effectively a probability of associating at each scan/unit of time.</li>
<li>At the moment, <code>SimuNet</code> only relies on a constant <span class="math inline">\(p\)</span> throughout all scans, which implies that it considers networks mostly static. <code>SimuNet</code> is however designed to accommodate time-dependent <span class="math inline">\(p\)</span>, to therefore simulate dynamic networks</li>
</ol>
</div>
<div id="the-biologicalsocial-meaning-of-p" class="section level4">
<h4 class="hasAnchor">
<a href="#the-biologicalsocial-meaning-of-p" class="anchor"></a>The biological/social meaning of <span class="math inline">\(p\)</span>
</h4>
<ol start="5" style="list-style-type: decimal">
<li>Edge weights in <em>social</em> networks usually quantify the relationship/proximity between two nodes. Under this “binomial” approach, an edge weight would more precisely quantify (or be proportional to) <strong>the probability that a pair of node is associated</strong> during each scan/segment of time. <span class="math inline">\(p\)</span> would be the resulting and estimable probability of association, probability that can result from the combination of many cognitive and social processes like kin preference, personality, etc. No assumption are required in how such <span class="math inline">\(p\)</span> emerges, but sampling to build weighted social networks would be intimately related to estimating this quantity.</li>
</ol>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#TODO: schematic from biological/behavioural/social drivers to p</span></code></pre></div>
</div>
<div id="toward-a-bayesian-framework" class="section level4">
<h4 class="hasAnchor">
<a href="#toward-a-bayesian-framework" class="anchor"></a>Toward a <strong>Bayesian</strong> framework</h4>
<ol start="6" style="list-style-type: decimal">
<li>In the context of a binomial variables, <span class="math inline">\(p\)</span> is often considered a <strong>known</strong> probability. The Binomial distribution then describes the probability that <span class="math inline">\(X\)</span> will take a value between 0 and <span class="math inline">\(n\)</span>. In the case of social networks and under our approach to edge weights, however, <span class="math inline">\(p\)</span> is what <strong>we want to estimate</strong>.</li>
</ol>
<p>Point 6. is the main consideration that led <code>SimuNet</code> to generate weighted networks under a Bayesian framework.</p>
</div>
</div>
</div>
<div id="estimating-edge-presence-probability-via-bayesian-inference" class="section level2">
<h2 class="hasAnchor">
<a href="#estimating-edge-presence-probability-via-bayesian-inference" class="anchor"></a>Estimating edge presence probability via Bayesian inference</h2>
<p>Estimating <span class="math inline">\(p\)</span> for a binomial variable <span class="math inline">\(X \sim Binomial(n,p)\)</span> from observations, e.g. the number of heads after <span class="math inline">\(n\)</span> coin-tosses that had probability <span class="math inline">\(p\)</span> of being head, is a common mathematical problem. See this <a href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval">Wikipedia article</a> on the subject.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#TODO: schematic from obs to a distribution of p</span></code></pre></div>
<p>It is however illusory to believe that we can find <strong>a single value</strong> that reflects both our <strong>best estimation</strong> of <span class="math inline">\(p\)</span> (a <strong>positional</strong> aspect of <span class="math inline">\(p\)</span>) and our <strong>confidence/certainty</strong> in this estimation. Intuitively, we also need a notion of spread around our estimation, either in the form of a confidence/credible interval, or even better, a distribution of <span class="math inline">\(p\)</span> on <span class="math inline">\([0,1]\)</span>.</p>
<p>Such a distribution of <span class="math inline">\(p\)</span> should:</p>
<ul>
<li>demonstrate the importance of <span class="math inline">\(n\)</span>, which can be viewed as a <strong>sampling effort</strong>, in determining how confident we are in an estimate of <span class="math inline">\(p\)</span>, i.e. how wide/narrow should the distribution of <span class="math inline">\(p\)</span> be around our best estimator.</li>
<li>be skewed when we <span class="math inline">\(p\)</span> is estimated from a value of <span class="math inline">\(X\)</span> close to <span class="math inline">\(0\)</span> or <span class="math inline">\(n\)</span>, while being bounded on <span class="math inline">\([0,1]\)</span>.</li>
</ul>
<p>Combining of the two previous points, when <span class="math inline">\(X\)</span> was exactly <span class="math inline">\(0\)</span> or <span class="math inline">\(n\)</span>, illustrates these issues of confidence/uncertainty: e.g. how confident should one be when estimating <span class="math inline">\(p=\frac{0}{n}=0\)</span> or <span class="math inline">\(p=\frac{n}{n}=1\)</span> when <span class="math inline">\(n=5\)</span> <em>versus</em> when <span class="math inline">\(n=5000\)</span>?</p>
<p>Hereafter, we demonstrate step-by-step how Bayesian statistics help finding such a distribution of <span class="math inline">\(p\)</span>.</p>
<div id="objective-a-posterior-distribution-of-p" class="section level3">
<h3 class="hasAnchor">
<a href="#objective-a-posterior-distribution-of-p" class="anchor"></a>Objective: a posterior distribution of <span class="math inline">\(p\)</span>
</h3>
<p>The problem of estimating the <strong>unknown binomial probability</strong> <span class="math inline">\(p\)</span> from the <strong>observation of an outcome</strong> and <strong>prior knowledge</strong> (or lack thereof) is well formalized under a Bayesian inference (see <a href="https://en.wikipedia.org/wiki/Binomial_distribution#Estimation_of_parameters">this Wikipedia page</a> and <a href="https://en.wikipedia.org/wiki/Beta_distribution#Bayesian_inference">this related one</a> on this topic). In short:</p>
<p>We want to obtain a <strong>posterior distribution</strong> of <span class="math inline">\(p\)</span> after observing <span class="math inline">\(X = a\)</span>, noted <span class="math inline">\(P(p|X=a)\)</span>, using Bayes’ theorem: <span class="math display">\[P(p|X=a) = \frac{P(X=a|p)P(p)}{P(X=a)},\]</span> with:</p>
<ul>
<li>
<span class="math inline">\(P(X=a|p)\)</span> being the <strong>(binomial) likelihood</strong> of observing <span class="math inline">\(X=a\)</span> when knowing <span class="math inline">\(p\)</span>
</li>
<li>
<span class="math inline">\(P(p)\)</span> being a <strong>prior distribution</strong> of <span class="math inline">\(p\)</span>, representing our prior knowledge of <span class="math inline">\(p\)</span>
</li>
<li>
<span class="math inline">\(P(X=a)\)</span> being a <strong>marginal likelihood</strong>, practically viewed as a “standardizing” constant, mathematically defined as an “averaged” likelihood of <span class="math inline">\(X=a\)</span> after considering all possible values of <span class="math inline">\(p\)</span>
</li>
</ul>
<p>Note: across the Bayes’ theorem, <span class="math inline">\(P(p)\)</span> is a shortcut for <span class="math inline">\(P(p = \pi),\forall\pi\in[0,1]\)</span> (or rather <span class="math inline">\(P(\pi_1\leq p \leq\pi_2]),(\pi_1,\pi_2)\in[0,1]^2\)</span> due to the continuous nature of <span class="math inline">\(p\)</span>). But since we are interested in a posterior distribution of <span class="math inline">\(p\)</span> over the whole <span class="math inline">\([0,1]\)</span> interval, it is common to omit such notation.</p>
</div>
<div id="tool-beta-conjugation" class="section level3">
<h3 class="hasAnchor">
<a href="#tool-beta-conjugation" class="anchor"></a>Tool: Beta conjugation</h3>
<p>The Beta distribution, can be used to model the <strong>prior and posterior distributions</strong> of the potential values <span class="math inline">\(p\)</span> can take:</p>
<ul>
<li>with relevant support for <span class="math inline">\(p \in [0,1]\)</span>.</li>
<li>The resulting notation is <span class="math inline">\(p \sim Beta(\alpha,\beta)\)</span>, where:
<ul>
<li>
<span class="math inline">\(\alpha\)</span> can represent the <strong>number of “successes”</strong>, e.g. heads in the case of the coin-tosses we mentioned, or times an edge is present (<span class="math inline">\(=1\)</span>) between two nodes in the case of scans</li>
<li>
<span class="math inline">\(\beta\)</span> can represent the <strong>number of “failures”</strong>, e.g. tails in the case of the coin-tosses we mentioned, or times an edge is absent (<span class="math inline">\(=0\)</span>) between two nodes in the case of scans.</li>
<li>Knowing the sampling effort <span class="math inline">\(n\)</span>, we can deduce <span class="math inline">\(\beta=n-\alpha\)</span> and <strong>only focus on <span class="math inline">\(\alpha\)</span></strong>.</li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#TODO: schematic Beta distribution for different values of alpha and beta</span></code></pre></div>
<p>The Beta distribution is the <strong>conjugate</strong> of the Binomial distribution in Bayesian statistics, which means that when using a <strong>Beta distribution as a prior</strong> with a Binomial likelihood, the resulting <strong>posterior</strong> probability distribution is <strong>also Beta distributed</strong>, which allows for an “iterative” update of our knowledge of the distribution of <span class="math inline">\(p\)</span>.</p>
</div>
<div id="determining-the-posterior-distribution-of-p" class="section level3">
<h3 class="hasAnchor">
<a href="#determining-the-posterior-distribution-of-p" class="anchor"></a>Determining the posterior distribution of <span class="math inline">\(p\)</span>
</h3>
<p>Therefore, prior knowledge, like having observed a previous outcome before trying to estimate <span class="math inline">\(p\)</span> from observations, can be used as a prior to further inform the posterior distribution of <span class="math inline">\(p\)</span>:</p>
<ul>
<li>The Beta distributed prior is formulated with <span class="math inline">\(\alpha_{prior}\)</span> and <span class="math inline">\(\beta_{prior}\)</span> representing previously observed <strong>(pseudo-)counts of “success” and “failures”</strong> (e.g. coming from previously published data)</li>
<li>We then observe <span class="math inline">\(X=a\)</span> after a sampling effort <span class="math inline">\(n\)</span>. The posterior distribution of <span class="math inline">\(p\)</span> is then: <span class="math display">\[P(p|X=a)=Beta(a+\alpha_{prior},(n-a)+\beta_{prior})\]</span>
</li>
<li>We can deduce that if we would use this knowledge as a prior distribution in a new experiment:
<ul>
<li>with <span class="math inline">\(\alpha' = a+\alpha_{prior}\)</span> and <span class="math inline">\(\beta' = n-a+\beta_{prior}\)</span>
</li>
<li>and observing <span class="math inline">\(X=a_{new}\)</span> after <span class="math inline">\(n_{new}\)</span> trials <span class="math display">\[P(p|X=a_{new})=Beta(a_{new}+\alpha',(n_{new}-a_{new})+\beta')=Beta(a_{new}+a+\alpha_{prior},(n_{new}+n)-(a_{new}+a)+\beta_{prior})\]</span> where <span class="math inline">\(a_{new}+a\)</span> is the total number of successes, <span class="math inline">\((n_{new}+n)\)</span> the total sampling effort, and <span class="math inline">\(\alpha_{prior}\)</span> and <span class="math inline">\(\beta_{prior}\)</span> the original Beta prior parameters</li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#TODO: schematic Bayesian inference combining prior + observation to form the posterior</span></code></pre></div>
<p>But what about when we <em>don’t</em> have prior knowledge on <span class="math inline">\(p\)</span>?</p>
<ul>
<li>Different <span class="math inline">\(\alpha_{prior}\)</span> and <span class="math inline">\(\beta_{prior}\)</span> can then be used as <strong>uninformative priors</strong> to end up with a posterior distribution of <span class="math inline">\(p\)</span> that is <strong>mostly driven by the observations</strong>. Arguing in favor of a choice of <span class="math inline">\(\alpha_{prior}\)</span> and <span class="math inline">\(\beta_{prior}\)</span> is beyond our scope, but two are commonly used:
<ul>
<li>
<span class="math inline">\(\alpha_{prior} = \beta_{prior} = 1\)</span>, and therefore <span class="math inline">\(Beta(1,1)\)</span>, is equivalent to a uniform distribution for <span class="math inline">\(p\)</span> over <span class="math inline">\([0,1]\)</span>
</li>
<li>
<span class="math inline">\(\alpha_{prior} = \beta_{prior} = \frac{1}{2}\)</span>, and therefore <span class="math inline">\(Beta(\frac{1}{2},\frac{1}{2})\)</span>, is called <a href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Jeffreys_interval">Jeffrey’s prior</a>, a widely used non-informative prior in Bayesian statistics</li>
<li>Both result in a <strong>symmetric prior</strong>, and their influence is quickly minor as <span class="math inline">\(n\)</span> increases</li>
</ul>
</li>
</ul>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#TODO: schematic Uninformative Beta priors</span></code></pre></div>
<p>We now obtained a posterior distribution of <span class="math inline">\(p\)</span> that best reflects our current knowledge of <span class="math inline">\(p\)</span> by combining our prior knowledge and updated it in view of observing <span class="math inline">\(X=a\)</span>.</p>
</div>
<div id="example-application-of-bayesian-inference-on-p" class="section level3">
<h3 class="hasAnchor">
<a href="#example-application-of-bayesian-inference-on-p" class="anchor"></a>Example application of Bayesian inference on <span class="math inline">\(p\)</span>
</h3>
<p>Imagine that two individuals have been observed associating 42 times after observing them 60 times:</p>
<ul>
<li>If we don’t have any prior knowledge, we can use either <span class="math inline">\(\alpha'=\beta'=1\)</span> or <span class="math inline">\(\alpha'=\beta'=\frac{1}{2}\)</span> as parameters of our Beta prior distribution. Let’s try with both.</li>
<li>Bayesian inference therefore indicate that our posterior distribution of <span class="math inline">\(p\)</span> on <span class="math inline">\([0,1]\)</span> is: <span class="math display">\[p|X=42 \sim Beta(42+\frac{1}{2},60 - 42+\frac{1}{2})=Beta(42.5,18.5)\]</span> <span class="math display">\[p|X=42 \sim Beta(42+1,60 - 42+1)=Beta(43,19)\]</span>
</li>
</ul>
<p>In R, <code>xbeta()</code> functions like <code><a href="https://rdrr.io/r/stats/Beta.html">dbeta()</a></code>, <code><a href="https://rdrr.io/r/stats/Beta.html">qbeta()</a></code> or <code><a href="https://rdrr.io/r/stats/Beta.html">rbeta()</a></code> from <code>stats</code> implements density, quantile and random number generation function related to the Beta distribution. Here is how the distribution looks like:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://wilkelab.org/cowplot/">cowplot</a></span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0.001</span><span class="op">)</span>,post <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0.001</span><span class="op">)</span> |&gt; <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="fl">42.5</span>,<span class="fl">18.5</span><span class="op">)</span>,prior <span class="op">=</span> <span class="st">"1/2"</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0.001</span><span class="op">)</span>,post <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0.001</span><span class="op">)</span> |&gt; <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="fl">43</span>,<span class="fl">19</span><span class="op">)</span>,prior <span class="op">=</span> <span class="st">" 1 "</span><span class="op">)</span>
<span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">p</span>,<span class="va">post</span>,colour <span class="op">=</span> <span class="va">prior</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>lty <span class="op">=</span> <span class="va">prior</span><span class="op">)</span>,size <span class="op">=</span> <span class="fl">1.1</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">7</span><span class="op">/</span><span class="fl">10</span>,lty <span class="op">=</span> <span class="st">"dashed"</span>,colour <span class="op">=</span> <span class="st">"grey50"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_ribbon.html">geom_ribbon</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>ymin <span class="op">=</span> <span class="fl">0</span>,ymax <span class="op">=</span> <span class="va">post</span>,fill <span class="op">=</span> <span class="va">prior</span><span class="op">)</span>,alpha <span class="op">=</span> <span class="fl">0.2</span>,colour <span class="op">=</span> <span class="cn">NA</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">41.5</span> <span class="op">/</span> <span class="fl">59</span>,y <span class="op">=</span> <span class="op">-</span><span class="fl">0.1</span><span class="op">)</span>,colour <span class="op">=</span> <span class="st">"tomato"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_errorbarh.html">geom_errorbarh</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="op">-</span><span class="fl">0.1</span>,xmin <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">qbeta</a></span><span class="op">(</span><span class="fl">0.025</span>,<span class="fl">42.5</span>,<span class="fl">18.5</span><span class="op">)</span>,xmax <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">qbeta</a></span><span class="op">(</span><span class="fl">0.975</span>,<span class="fl">42.5</span>,<span class="fl">18.5</span><span class="op">)</span><span class="op">)</span>,
                 colour <span class="op">=</span> <span class="st">"tomato"</span>,height <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">42</span> <span class="op">/</span> <span class="fl">60</span>,y <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>,colour <span class="op">=</span> <span class="st">"royalblue"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_errorbarh.html">geom_errorbarh</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fl">0.1</span>,xmin <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">qbeta</a></span><span class="op">(</span><span class="fl">0.025</span>,<span class="fl">43</span>,<span class="fl">19</span><span class="op">)</span>,xmax <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">qbeta</a></span><span class="op">(</span><span class="fl">0.975</span>,<span class="fl">43</span>,<span class="fl">19</span><span class="op">)</span><span class="op">)</span>,
                 colour <span class="op">=</span> <span class="st">"royalblue"</span>,height <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_colour_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"royalblue"</span>,<span class="st">"tomato"</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_fill_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"royalblue"</span>,<span class="st">"tomato"</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_linetype_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"2424"</span>,<span class="st">"2828"</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/guides.html">guides</a></span><span class="op">(</span>linetype <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>y <span class="op">=</span> <span class="st">"Posterior distributions"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_minimal_grid.html">theme_minimal_grid</a></span><span class="op">(</span><span class="fl">15</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>plot.background <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_rect</a></span><span class="op">(</span>fill <span class="op">=</span> <span class="st">'white'</span>, colour <span class="op">=</span> <span class="cn">NA</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p><img src="bayesian_framework_files/figure-html/beta_exp1-1.png" width="700"></p>
<p>where the dots + intervals are the modes and <span class="math inline">\([2.5\%,97.5\%]\)</span> inter-quantile intervals of the two posterior distributions, and the dashed vertical grey line represents <span class="math inline">\(\frac{42}{60}\)</span>.</p>
<p>It is visible that the choice between either of the two uninformative priors has already little impact on the resulting posterior for <span class="math inline">\(n = 60\)</span>.</p>
</div>
<div id="the-impact-of-sampling-effort-n" class="section level3">
<h3 class="hasAnchor">
<a href="#the-impact-of-sampling-effort-n" class="anchor"></a>The impact of sampling effort <span class="math inline">\(n\)</span>
</h3>
<p>Let’s see how the distribution changes for a similar estimation of <span class="math inline">\(p\)</span> but with lower sample size <span class="math inline">\(n\)</span>, with <span class="math inline">\(X=7\)</span> and <span class="math inline">\(n=10\)</span> (<span class="math inline">\(\frac{42}{60}=\frac{7}{10}=0.7\)</span>):</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0.001</span><span class="op">)</span>,post <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0.001</span><span class="op">)</span> |&gt; <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="fl">7.5</span>,<span class="fl">3.5</span><span class="op">)</span>,prior <span class="op">=</span> <span class="st">"1/2"</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0.001</span><span class="op">)</span>,post <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">0.001</span><span class="op">)</span> |&gt; <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="fl">8</span>,<span class="fl">4</span><span class="op">)</span>,prior <span class="op">=</span> <span class="st">" 1 "</span><span class="op">)</span>
<span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">p</span>,<span class="va">post</span>,colour <span class="op">=</span> <span class="va">prior</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>lty <span class="op">=</span> <span class="va">prior</span><span class="op">)</span>,size <span class="op">=</span> <span class="fl">1.1</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">7</span><span class="op">/</span><span class="fl">10</span>,lty <span class="op">=</span> <span class="st">"dashed"</span>,colour <span class="op">=</span> <span class="st">"grey50"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_ribbon.html">geom_ribbon</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>ymin <span class="op">=</span> <span class="fl">0</span>,ymax <span class="op">=</span> <span class="va">post</span>,fill <span class="op">=</span> <span class="va">prior</span><span class="op">)</span>,alpha <span class="op">=</span> <span class="fl">0.2</span>,colour <span class="op">=</span> <span class="cn">NA</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">6.5</span> <span class="op">/</span> <span class="fl">9</span>,y <span class="op">=</span> <span class="op">-</span><span class="fl">0.05</span><span class="op">)</span>,colour <span class="op">=</span> <span class="st">"tomato"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_errorbarh.html">geom_errorbarh</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="op">-</span><span class="fl">0.05</span>,xmin <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">qbeta</a></span><span class="op">(</span><span class="fl">0.025</span>,<span class="fl">7.5</span>,<span class="fl">3.5</span><span class="op">)</span>,xmax <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">qbeta</a></span><span class="op">(</span><span class="fl">0.975</span>,<span class="fl">7.5</span>,<span class="fl">3.5</span><span class="op">)</span><span class="op">)</span>,
                 colour <span class="op">=</span> <span class="st">"tomato"</span>,height <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">7</span> <span class="op">/</span> <span class="fl">10</span>,y <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span>,colour <span class="op">=</span> <span class="st">"royalblue"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_errorbarh.html">geom_errorbarh</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fl">0.05</span>,xmin <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">qbeta</a></span><span class="op">(</span><span class="fl">0.025</span>,<span class="fl">8</span>,<span class="fl">4</span><span class="op">)</span>,xmax <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">qbeta</a></span><span class="op">(</span><span class="fl">0.975</span>,<span class="fl">8</span>,<span class="fl">4</span><span class="op">)</span><span class="op">)</span>,
                 colour <span class="op">=</span> <span class="st">"royalblue"</span>,height <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_colour_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"royalblue"</span>,<span class="st">"tomato"</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_fill_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"royalblue"</span>,<span class="st">"tomato"</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_linetype_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"2424"</span>,<span class="st">"2828"</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/guides.html">guides</a></span><span class="op">(</span>linetype <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>y <span class="op">=</span> <span class="st">"Posterior distributions"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://wilkelab.org/cowplot/reference/theme_minimal_grid.html">theme_minimal_grid</a></span><span class="op">(</span><span class="fl">15</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>plot.background <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_rect</a></span><span class="op">(</span>fill <span class="op">=</span> <span class="st">'white'</span>, colour <span class="op">=</span> <span class="cn">NA</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p><img src="bayesian_framework_files/figure-html/beta_exp2-1.png" width="700"></p>
<p>The posterior distributions are wider, and at such low sampling effort, a larger difference is observed between using one uninformative prior or the other.</p>
</div>
</div>
<div id="simulating-scans-after-inferring-p" class="section level2">
<h2 class="hasAnchor">
<a href="#simulating-scans-after-inferring-p" class="anchor"></a>Simulating scans after inferring <span class="math inline">\(p\)</span>
</h2>
<p>But how to <em>use</em> this inferred distribution of <span class="math inline">\(p\)</span>? What value of <span class="math inline">\(p\)</span> to use when randomly simulating if an edge should be <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>, while still reflecting the gained knowledge on the <strong>confidence/uncertainty of <span class="math inline">\(p\)</span></strong>?</p>
<p>As seen in the previous examples, with a uniform prior <span class="math inline">\(Beta(1,1)\)</span>, the mode of the posterior distribution is for <span class="math inline">\(p=\frac{a}{n}\)</span>, and that using Jeffrey’s prior leads to posterior converging to similar posterior distributions when <span class="math inline">\(n\)</span> increases. Simply using the mode does not reflect the confidence/uncertainty, or in other words, how wide/narrow around <span class="math inline">\(\frac{a}{n}\)</span> is the posterior distribution of <span class="math inline">\(p\)</span> for different values of <span class="math inline">\(n\)</span>, e.g. if comparing <span class="math inline">\(\frac{7}{10}=0.7\)</span> and <span class="math inline">\(\frac{42}{60}=0.7\)</span>.</p>
<div id="mixing-beta-and-binomial-distributions" class="section level3">
<h3 class="hasAnchor">
<a href="#mixing-beta-and-binomial-distributions" class="anchor"></a>Mixing Beta and Binomial distributions</h3>
<p>We can intuitively see that <strong>a “point” estimate of <span class="math inline">\(p\)</span> might not represent <span class="math inline">\(p\)</span> variability</strong> as well as relying on values of <span class="math inline">\(p\)</span> that make <strong>use of the whole posterior distribution</strong>.</p>
<p>To overcome this issue, we propose here to:</p>
<ol style="list-style-type: decimal">
<li>draw <strong>a random value</strong> of <span class="math inline">\(p\)</span> from the posterior distribution</li>
<li>draw <strong>all the scans</strong> of the simulation with this random <span class="math inline">\(p\)</span>
</li>
<li>repeat steps 1.-2. if we need a new simulation.</li>
</ol>
<p>In other words, we can say that:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(p\sim Beta(a+\alpha_{prior},n-a+\beta_{prior})\)</span></li>
<li><span class="math inline">\(\forall x_{simu,i},x_{simu,i} \sim Binomial(n_{simu},p),i \in [\![1,n_{simu}]\!]\)</span></li>
<li>and later obtain <span class="math inline">\(X_{simu}=\Sigma x_{simu,i}\)</span>
</li>
</ol>
<p>This process is by definition a <a href="https://en.wikipedia.org/wiki/Beta-binomial_distribution"><strong>Beta-Binomial process</strong></a>, with <span class="math display">\[X_{simu} \sim Beta\!-\!Binomial(a+\alpha_{prior},n-a+\beta_{prior},n_{simu})\]</span></p>
<p>Note that for a given simulation of <span class="math inline">\(n_{simu}\)</span> scans, we draw <strong>a single random <span class="math inline">\(p\)</span></strong> because, compared to only drawing a single value of <span class="math inline">\(p\)</span> <strong>before each scan</strong>, this adds additional variance to <span class="math inline">\(X_{simu}\)</span>, which comes from the <strong>combination of the uncertainty over <span class="math inline">\(p\)</span></strong>, and the added <strong>variability from sampling new data</strong>. See <a href="https://stats.stackexchange.com/q/105908">this post on StackOverflow</a> for more details on the difference between these two processes.</p>
</div>
<div id="why-not-simply-drawing-ege-weights-from-a-beta-binomial-distribution" class="section level3">
<h3 class="hasAnchor">
<a href="#why-not-simply-drawing-ege-weights-from-a-beta-binomial-distribution" class="anchor"></a>Why not simply drawing ege weights from a Beta-Binomial distribution?</h3>
<p><code>SimuNet</code> aims at simulating a sequence of <strong>binary</strong> scans, for which each edge is either 0 or 1. This is because we believe that phenomenon or manipulations can happen at <strong>any of these binary scans</strong>, with potential impact on network metrics of interest after aggregating these binary scans into edge weights.</p>
<p>For instance, missing an edge during sampling - e.g. two individuals are not visible, and it is not possible to assess if the individuals are associating/interacting or not, i.e. that the edge between them is 0 or 1 - happens or not <strong>during a single scan</strong>.</p>
<p>Simulating sequences of binary scans allows <strong>designing and performing</strong> network manipulations <strong>more flexibly</strong> at a “granular” level, in comparison of obtaining directly an integer for the edge weight.</p>
<p><code>SimuNet</code> keeps track as much as possible of the <strong>“intermediate” steps leading to a weighted network</strong>, especially through the use of an attribute list <code>attrs</code>. This way, we hope that <code>SimuNet</code> can be <strong>used and adapted to generate varied network simulations</strong>.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#TODO: schematic comparison drawing edges from Beta-Binomial vs SimuNet's step-by-step approach</span></code></pre></div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Kenneth Keuk.</p>
</div>

<div class="pkgdown">
  <p>Made with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1, using <a href="https://preferably.amirmasoudabdol.name/?source=footer">preferably</a> template.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
